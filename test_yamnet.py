import numpy as np
import sounddevice as sd
import scipy.signal
import csv
import tflite_runtime.interpreter as tflite

# =============================
# Cáº¥u hÃ¬nh
# =============================
SAMPLE_RATE = 16000  # YAMNet yÃªu cáº§u 16kHz
DURATION = 2         # Ghi Ã¢m 2 giÃ¢y
MODEL_PATH = "lite-model_yamnet_tflite_1.tflite"
CLASS_MAP_PATH = "yamnet_class_map.csv"

# =============================
# HÃ m há»— trá»£
# =============================
def record_audio():
    print("ğŸ™ï¸ Äang ghi Ã¢m...")
    audio = sd.rec(int(DURATION * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype="float32")
    sd.wait()
    print("âœ… Ghi Ã¢m xong!")
    return np.squeeze(audio)

def load_labels(path):
    labels = []
    with open(path, newline="") as f:
        reader = csv.reader(f)
        next(reader)  # bá» dÃ²ng tiÃªu Ä‘á»
        for row in reader:
            labels.append(row[2])  # cá»™t thá»© 3: display_name
    return labels

# =============================
# Main
# =============================
if __name__ == "__main__":
    # 1. Load model
    interpreter = tflite.Interpreter(model_path=MODEL_PATH)
    interpreter.allocate_tensors()
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    # 2. Load labels
    class_names = load_labels(CLASS_MAP_PATH)

    # 3. Ghi Ã¢m
    waveform = record_audio()

    # 4. ÄÆ°a vÃ o model
    # YAMNet input shape: (None,) float32 waveform at 16kHz
    waveform = waveform.astype(np.float32)

    interpreter.set_tensor(input_details[0]['index'], waveform)
    interpreter.invoke()

    # 5. Láº¥y output
    scores = interpreter.get_tensor(output_details[0]['index'])[0]  # (N, 521 classes)
    mean_scores = np.mean(scores, axis=0)

    # 6. In top-5
    top5 = mean_scores.argsort()[-5:][::-1]
    print("\nğŸ”Š Káº¿t quáº£ phÃ¢n loáº¡i:")
    for i in top5:
        print(f"- {class_names[i]} ({mean_scores[i]:.3f})")
