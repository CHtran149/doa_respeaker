import numpy as np
import sounddevice as sd
import tflite_runtime.interpreter as tflite
import csv

# =========================
# Cáº¥u hÃ¬nh
# =========================
SAMPLE_RATE = 16000
DURATION = 1.0        # giÃ¢y
TARGET_SAMPLES = int(SAMPLE_RATE * DURATION)

# =========================
# Load nhÃ£n YAMNet
# =========================
class_names = []
with open("yamnet_class_map.csv", "r") as f:
    reader = csv.reader(f)
    next(reader)  # bá» header
    for row in reader:
        class_names.append(row[2])

# =========================
# Load model TFLite
# =========================
interpreter = tflite.Interpreter(model_path="yamnet.tflite")
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# =========================
# Ghi Ã¢m
# =========================
print("ðŸŽ™ï¸ Äang ghi Ã¢m...")
recording = sd.rec(int(SAMPLE_RATE * DURATION), samplerate=SAMPLE_RATE, channels=1, dtype="float32")
sd.wait()
print("âœ… Ghi Ã¢m xong!")

# Chuyá»ƒn sang vector 1D
waveform = np.squeeze(recording)

# Chuáº©n hÃ³a Ä‘á»™ dÃ i Ä‘Ãºng 15600 máº«u
if len(waveform) > TARGET_SAMPLES:
    waveform = waveform[:TARGET_SAMPLES]
elif len(waveform) < TARGET_SAMPLES:
    waveform = np.pad(waveform, (0, TARGET_SAMPLES - len(waveform)))

# Äáº£m báº£o float32
waveform = waveform.astype(np.float32)

# =========================
# Cháº¡y model
# =========================
interpreter.set_tensor(input_details[0]['index'], waveform)
interpreter.invoke()
predictions = interpreter.get_tensor(output_details[0]['index'])[0]

# =========================
# Láº¥y top-5 káº¿t quáº£
# =========================
top5_idx = np.argsort(predictions)[::-1][:5]
print("\nðŸ”Š Káº¿t quáº£ phÃ¢n loáº¡i:")
for i in top5_idx:
    print(f"- {class_names[i]} ({predictions[i]:.2f})")
