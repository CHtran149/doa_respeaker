import sounddevice as sd
import numpy as np
import tflite_runtime.interpreter as tflite
import csv

# =====================
# Cáº¥u hÃ¬nh
# =====================
MODEL_PATH = "lite-model_yamnet_tflite_1.tflite"
CLASS_MAP_PATH = "yamnet_class_map.csv"
SAMPLE_RATE = 16000
TARGET_SAMPLES = 15600   # input chuáº©n cá»§a YAMNet (~0.975s)

# =====================
# Load class map
# =====================
class_names = []
with open(CLASS_MAP_PATH, "r") as f:
    reader = csv.reader(f)
    next(reader)  # bá» header
    for row in reader:
        class_names.append(row[2])  # cá»™t Display Name

# =====================
# Load model
# =====================
interpreter = tflite.Interpreter(model_path=MODEL_PATH)
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# =====================
# Ghi Ã¢m 1 giÃ¢y
# =====================
print("ðŸŽ™ï¸ Äang ghi Ã¢m...")
waveform = sd.rec(int(SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype=np.float32)
sd.wait()
print("âœ… Ghi Ã¢m xong!")

waveform = np.squeeze(waveform)  # (16000,)

# =====================
# Chuáº©n hÃ³a thÃ nh 15600 máº«u
# =====================
if len(waveform) > TARGET_SAMPLES:
    waveform = waveform[:TARGET_SAMPLES]
elif len(waveform) < TARGET_SAMPLES:
    waveform = np.pad(waveform, (0, TARGET_SAMPLES - len(waveform)))

# ThÃªm batch dimension
waveform = np.expand_dims(waveform, axis=0)  # (1, 15600)

# =====================
# Cháº¡y model
# =====================
interpreter.set_tensor(input_details[0]['index'], waveform)
interpreter.invoke()
predictions = interpreter.get_tensor(output_details[0]['index'])[0]  # (521,)

# =====================
# Láº¥y nhÃ£n top-1
# =====================
top_index = np.argmax(predictions)
top_score = predictions[top_index]
top_class = class_names[top_index]

print(f"ðŸ”Š Ã‚m thanh dá»± Ä‘oÃ¡n: {top_class} (score={top_score:.2f})")
